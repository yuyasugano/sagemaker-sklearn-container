{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 prefix\n",
    "bucket = 'sagemaker-getting-start-test'\n",
    "prefix = 'sagemaker/scikit-iris'\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "# Get a SageMaker-compatible role used by this Notebook Instance.\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn import datasets\n",
    "\n",
    "# Load Iris dataset, then join labels and features\n",
    "iris = datasets.load_iris()\n",
    "joined_iris = np.insert(iris.data, 0, iris.target, axis=1)\n",
    "\n",
    "# Create directory and write csv\n",
    "os.makedirs('./data', exist_ok=True)\n",
    "np.savetxt('./data/iris.csv', joined_iris, delimiter=',', fmt='%1.1f, %1.3f, %1.3f, %1.3f, %1.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIRECTORY = 'data'\n",
    "train_input = sagemaker_session.upload_data(WORK_DIRECTORY, key_prefix=\"{}/{}\".format(prefix, WORK_DIRECTORY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-17 05:28:07 Starting - Starting the training job...\n",
      "2019-11-17 05:28:08 Starting - Launching requested ML instances.........\n",
      "2019-11-17 05:29:39 Starting - Preparing the instances for training...\n",
      "2019-11-17 05:30:24 Downloading - Downloading input data\n",
      "2019-11-17 05:30:24 Training - Downloading the training image...\n",
      "2019-11-17 05:31:07 Uploading - Uploading generated training model.\u001b[31mStarting the training.\u001b[0m\n",
      "\u001b[31mX shape: (150,4)\u001b[0m\n",
      "\u001b[31my shape: (150,1)\u001b[0m\n",
      "\u001b[31mTraining complete.\u001b[0m\n",
      "\n",
      "2019-11-17 05:31:12 Completed - Training job completed\n",
      "Training seconds: 54\n",
      "Billable seconds: 54\n"
     ]
    }
   ],
   "source": [
    "account = sagemaker_session.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = sagemaker_session.boto_session.region_name\n",
    "image_full = '{}.dkr.ecr.{}.amazonaws.com/sklearn-container:latest'.format(account, region)\n",
    "\n",
    "clf = sagemaker.estimator.Estimator(image_full, role, 1, 'ml.c4.2xlarge', \n",
    "                                    output_path=\"s3://{}/output\".format(sagemaker_session.default_bucket()),\n",
    "                                    sagemaker_session=sagemaker_session)\n",
    " \n",
    "# training with the gradient boosting classifier model\n",
    "clf.fit(train_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using already existing model: sklearn-container-2019-11-17-05-28-07-002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import csv_serializer\n",
    "predictor = clf.deploy(initial_instance_count=1, instance_type=\"ml.m4.xlarge\", serializer=csv_serializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data: (29, 5)\n",
      "test_X: (29, 4)\n",
      "test_y: (29,)\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "shape = pd.read_csv(\"./data/iris.csv\", header=None)\n",
    "a = [50*i for i in range(3)]\n",
    "b = [40+i for i in range(10)]\n",
    "indices = [i+j for i,j in itertools.product(a,b)]\n",
    "\n",
    "test_data = shape.iloc[indices[:-1]]\n",
    "print(\"test_data: {}\".format(test_data.shape))\n",
    "test_X = test_data.iloc[:,1:]\n",
    "test_y = test_data.iloc[:,0]\n",
    "print(\"test_X: {}\".format(test_X.shape))\n",
    "print(\"test_y: {}\".format(test_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values:\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "\n",
      "test_y values:\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted values:\\n{}\".format(predictor.predict(test_X.values).decode('utf-8')))\n",
    "print(\"test_y values:\\n{}\".format(test_y.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
